{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58473dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import contractions\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09caa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/aiffel/aiffel/goingdeeper/'\n",
    "df = pd.read_excel(path+\"ko_en_data.xlsx\")\n",
    "text_df = df[['원문','번역문']]\n",
    "text_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776e0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "def ko_preprocess(sentence):\n",
    "    w = sentence.strip()\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    w = re.sub(r\"[^가-힣?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    mecab = Mecab()\n",
    "    w = mecab.morphs(w)\n",
    "    w = \" \".join(w)\n",
    "    w = \"<start> \" + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "def en_preprocess(sentence):\n",
    "    w = contractions.fix(sentence)\n",
    "    w = sentence.lower().strip()\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = \"<start> \" + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e091e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200011/200011 [04:28<00:00, 743.70it/s]\n",
      "/tmp/ipykernel_161/2021928097.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df[\"ko\"] = text_df.원문.progress_apply(ko_preprocess)\n",
      "100%|██████████| 200011/200011 [00:08<00:00, 23802.88it/s]\n",
      "/tmp/ipykernel_161/2021928097.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['en'] = text_df.번역문.progress_apply(en_preprocess)\n"
     ]
    }
   ],
   "source": [
    "text_df[\"ko\"] = text_df.원문.progress_apply(ko_preprocess)\n",
    "text_df['en'] = text_df.번역문.progress_apply(en_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d7de0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         <start> 스키너 가 말 한 보상 은 대부분 눈 으로 볼 수 있 는 현물 이 다...\n",
       "1         <start> 심지어 어떤 문제 가 발생 할 건지 도 어느 정도 예측 이 가능 하 ...\n",
       "2         <start> 오직 하나님 만 이 그 이유 를 제대로 알 수 있 을 겁니다 . <end>\n",
       "3         <start> 중국 의 논쟁 을 보 며 간과 해선 안 될 게 기업 들 의 고충 이 ...\n",
       "4         <start> 박자 가 느린 노래 는 오랜 시간 이 지나 뜨 는 경우 가 있 다 ....\n",
       "                                ...                        \n",
       "200006    <start> 당시 에 는 경찰 의 금지 통보 로 청와대 근처 집회 가 불 가능 하...\n",
       "200007    <start> 양승태 대법원 과 박근혜 청와대 의 대표 적 재판 거래 의혹 사건 으...\n",
       "200008    <start> 윤석열 서울 중앙지 검장 이 일 국정 감사 에 출석 해 적폐 수사 호...\n",
       "200009    <start> 대법원 에 재 상고 된 지 년 이 넘 도록 재판 이 지연 되 면서 양...\n",
       "200010    <start> 양승태 대법원 은 민사 소송 규칙 까지 고쳐 외교부 가 대 법원 에 ...\n",
       "Name: ko, Length: 200011, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "820118c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\")\n",
    "    tokenizer.fit_on_texts(sentence)\n",
    "    tensor = tokenizer.texts_to_sequences(sentence)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, tokenizer\n",
    "\n",
    "ko_tensor, ko_tokenizer = tokenize(text_df.ko[:50000].to_list())\n",
    "en_tensor, en_tokenizer = tokenize(text_df.en[:50000].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "faa01459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ----> <start>\n",
      "24750 ----> 스키너\n",
      "8 ----> 가\n",
      "61 ----> 말\n",
      "16 ----> 한\n",
      "1598 ----> 보상\n",
      "12 ----> 은\n",
      "444 ----> 대부분\n",
      "282 ----> 눈\n",
      "19 ----> 으로\n",
      "288 ----> 볼\n",
      "27 ----> 수\n",
      "13 ----> 있\n",
      "6 ----> 는\n",
      "9410 ----> 현물\n",
      "1 ----> 이\n",
      "5 ----> 다\n",
      "2 ----> .\n",
      "4 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "convert( ko_tokenizer,ko_tensor[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0ac9af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 10000 40000 10000\n"
     ]
    }
   ],
   "source": [
    "ko_train, ko_test, en_train, en_test = train_test_split(ko_tensor, en_tensor, test_size=0.2)\n",
    "print(len(ko_train),len(ko_test),len(en_train),len(en_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e3955c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(ko_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(ko_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units=1024\n",
    "ko_vocab_size = len(ko_tokenizer.word_index)+1\n",
    "en_vocab_size = len(en_tokenizer.word_index)+1\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "dataset = tf.data.Dataset.from_tensor_slices((ko_train, en_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True, num_parallel_calls=AUTO).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "686856af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1568e302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 61]), TensorShape([64, 46]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1cca5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 61, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(ko_vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# 샘플 입력\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f56ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # 쿼리 은닉 상태(query hidden state)는 (batch_size, hidden size)쌍으로 이루어져 있습니다.\n",
    "        # query_with_time_axis은 (batch_size, 1, hidden size)쌍으로 이루어져 있습니다.\n",
    "        # values는 (batch_size, max_len, hidden size)쌍으로 이루어져 있습니다.\n",
    "        # 스코어(score)계산을 위해 덧셈을 수행하고자 시간 축을 확장하여 아래의 과정을 수행합니다.\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다.\n",
    "        # score를 self.V에 적용하기 때문에 마지막 축에 1을 얻습니다.\n",
    "        # self.V에 적용하기 전에 텐서는 (batch_size, max_length, units)쌍으로 이루어져 있습니다.\n",
    "        score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다. \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # 덧셈이후 컨텍스트 벡터(context_vector)는 (batch_size, hidden_size)쌍으로 이루어져 있습니다.\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "179794ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f79422a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 61, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "31e6d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # 어텐션을 사용합니다.\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "            # enc_output는 (batch_size, max_length, hidden_size)쌍으로 이루어져 있습니다.\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # 임베딩층을 통과한 후 x는 (batch_size, 1, embedding_dim)쌍으로 이루어져 있습니다.\n",
    "        x = self.embedding(x)\n",
    "\n",
    "    # 컨텍스트 벡터와 임베딩 결과를 결합한 이후 x의 형태는 (batch_size, 1, embedding_dim + hidden_size)쌍으로 이루어져 있습니다.\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # 위에서 결합된 벡터를 GRU에 전달합니다.\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "    # output은 (batch_size * 1, hidden_size)쌍으로 이루어져 있습니다.\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output은 (batch_size, vocab)쌍으로 이루어져 있습니다.\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1f1ee5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 32388)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(en_vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec7076e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9a3e53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6f78f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([en_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # 교사 강요(teacher forcing) - 다음 입력으로 타겟을 피딩(feeding)합니다.\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # 교사 강요(teacher forcing)를 사용합니다.\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2a5cd714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 3.1206\n",
      "Time taken for 1 epoch 543.1633012294769 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 2 Loss 2.7283\n",
      "Time taken for 1 epoch 507.9747669696808 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 3 Loss 2.4837\n",
      "Time taken for 1 epoch 504.60764384269714 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 4 Loss 2.2815\n",
      "Time taken for 1 epoch 513.382479429245 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 5 Loss 2.0982\n",
      "Time taken for 1 epoch 505.8356499671936 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 6 Loss 1.9177\n",
      "Time taken for 1 epoch 513.7783784866333 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 7 Loss 1.7369\n",
      "Time taken for 1 epoch 505.9370048046112 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 8 Loss 1.5602\n",
      "Time taken for 1 epoch 513.9078900814056 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 9 Loss 1.3933\n",
      "Time taken for 1 epoch 505.9334077835083 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 10 Loss 1.2332\n",
      "Time taken for 1 epoch 513.6205575466156 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 11 Loss 1.0855\n",
      "Time taken for 1 epoch 506.13149309158325 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 12 Loss 0.9582\n",
      "Time taken for 1 epoch 512.3279712200165 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 13 Loss 0.8273\n",
      "Time taken for 1 epoch 504.98492455482483 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 14 Loss 0.7199\n",
      "Time taken for 1 epoch 512.7945709228516 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 15 Loss 0.6168\n",
      "Time taken for 1 epoch 504.877236366272 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 16 Loss 0.5207\n",
      "Time taken for 1 epoch 511.9705455303192 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 17 Loss 0.4456\n",
      "Time taken for 1 epoch 505.2839901447296 sec\n",
      "\n",
      "patience_count + 1\n",
      "Epoch 18 Loss 0.3746\n",
      "Time taken for 1 epoch 505.5443456172943 sec\n",
      "\n",
      "patience_count + 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_161/1734977273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpatience_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    pre_loss = 0\n",
    "    current_loss = 0\n",
    "    patience_limit = 4\n",
    "    patience_count = 0\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "           \n",
    "        \n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    \n",
    "        \n",
    "  # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    \n",
    "    current_loss = batch_loss.numpy()\n",
    "    if current_loss > pre_loss:\n",
    "        patience_count += 1\n",
    "        print(\"patience_count + 1\")\n",
    "        pre_loss = current_loss\n",
    "    pre_loss = current_loss\n",
    "    if patience_count > patience_limit:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c84d88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_max_len = ko_tensor.shape[1]\n",
    "en_max_len = en_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2196f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((en_max_len, ko_max_len))\n",
    "\n",
    "    sentence = ko_preprocess(sentence)\n",
    "\n",
    "    inputs = [ko_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=ko_max_len,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([en_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(en_max_len):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # 나중에 어텐션 가중치를 시각화하기 위해 어텐션 가중치를 저장합니다.\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += en_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if en_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "    # 예측된 ID를 모델에 다시 피드합니다.\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "# 어텐션 가중치를 그리기 위한 함수입니다.\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f3941158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff25434c3d0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0bbb458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c0f07f08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 한국 은 훌륭 한 나라 이 다 <end>\n",
      "Predicted translation: korea is korea . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161/4081095973.py:49: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_161/4081095973.py:50: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54988 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47469 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45208 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 46972 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54988 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47469 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45208 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 46972 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAHFCAYAAACU1Q+8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcT0lEQVR4nO3de7StdV3v8c8XNpcAAe8aeSG8Vqghx3uIB4vqUCM7nLISURxijlN5hsNqNMr0jDKPiXk81RjH3akQ0czroDQ1TUxTyIwjRF65SIe8gYDA5g7f88ecO1fLfVkbWfNZ6zdfrzH22Gs9zzPn/D577s168zzzmbO6OwAAbG57TT0AAADfPlEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFEHADAAUQcAMABRBwAwAFE3kap6aFV9qKqOnHoWAGDzE3XTOTnJsUlOmXgOAGAA1d1Tz7B0qqqSfDHJB5L8WJLv7O7bJx0KANjUHKmbxrFJ7pbkl5LcluRHJ50GANj0RN00Tk7y9u6+Iclb5t8DANxpTr8uWFUdmOTLSf5Td3+0qh6T5Jwk9+/ua6acDQDYvBypW7z/nOTK7v5oknT3p5J8IckzpxwKANi9qjqwqp5dVYdMPctqom7xTkpy5qplZyZ5zuJHAQD20E8l+dPMfp5vKE6/LlBVPSDJpUke2d1fWLH8uzK7GvZ7uvvzE40HAOxGVZ2d5L5Jbujuo6eeZyVRBwCwBlX14CSfT/K4JOcmOaq7Pz3pUCs4/bpgVfXA+fvU7XDdoucBANbspCQfnb8e/q+ywd69QtQt3qVJ7r16YVXdc74OANiYnp3kjfOv35Tk53Z2oGYKom7xKsmOznkflOSmBc8CAKxBVT0pyf2TvH2+6C+THJDk6ZMNtcqWqQdYFlX1v+ZfdpJXVtUNK1bvndn5+U8tei4AYE1OTnJWd1+fJN19S1W9NbN3r/jAlINtJ+oW58j575XkkUluWbHuliTnJTlt0UMBALtWVftl9lYmP7Nq1ZlJ3l9VB22PvSm5+nWB5ufd35rklO6+bup5AIDdq6p7ZfY57Wd29x2r1j0ryQe7+yuTDLdyFlG3OFW1d2avm3v0RroEGgDY/FwosUDdfXuSy5LsO/UsAMBYHKlbsKo6ObNz8s/q7iunngcA2LGqujQ7fseKb9Hd373O4+yWCyUW7yVJDk/yr1V1eZJtK1d296MmmQoAWO0PVnx9UJIXJ/lEknPmy56Y2btXvGbBc+2QqFu8t+9+EwBgat39b7FWVacneVV3/87Kbarq15J874JH2yGnXwEAdqOqrs3ss14vWrX8IUnO6+6Dp5nsm1woAQCwe9uSHLuD5ccmuWEHyxfO6dcFq6p9k/x6ZhdLPDDJPivXd/feU8wFAOzSa5P8YVUdneTc+bInZPZJEy+faqiVRN3i/VaSn07yysz+gvxykgcneWaSl043FgCwM939u1X1xSQvyuzTJZLkM0lO7u63TjbYCl5Tt2Dzy6Nf2N3vq6rrkjymuy+uqhcmOa67T5x4RABgE3KkbvHum2T7p0lcn+TQ+dfvS/KqKQYCANauqg7NqusSuvuqaab5JhdKLN6/JPnO+dcXJTl+/vUTk9w4yUQAwC5V1YOq6r1VdWOSrye5Yv7ryvnvk3OkbvHeleS4zF5k+bokf1ZVz09yWJJXTzkYALBTf5rZ2bXnJflS1vhJE4vkNXUTq6rHJ3lyks9397unngcA+FZVdX2SJ3T3hVPPsjOO1C1YVR2T5OPdfVuSdPffJ/n7qtpSVcd090emnRAA2IFLk+w39RC74jV1i3d2knvsYPkh83UAwMbzoiSvnH+CxIbkSN3iVXZ8Hv6emb1bNQCw8ZyV2ZG6z1XVzUluW7lyI3xMmKhbkKr6i/mXneTM+V+I7fZO8n1JPr7wwQCAtfiFqQfYHVG3OF+f/15Jrs6/f/uSW5L8XZI/WvRQAMDudfcbpp5hd1z9umBV9bIkp3W3U60AsIlU1X2TnJTkiCQv7e4rq+rJSb7U3ZdOO52oW7iq2itJuvuO+ff3S3JCkk93t9OvALABVdVjk/xNZlfBfm+SR3T3JVX18iQP6+6fnXK+RNQtXFW9N8n7uvt1VXVQks8mOTDJQUme191nTDrgXaiqvjN7dor/5u7+6nrNw/ryfC8XzzfLpqrOTvKR7n7Z/LPbHz2PuicmeUt3P2jiEb2mbgJHJ/mV+dc/meTaJIcn+bkkL0kyTNQl+VCS8zJ7HeFaHJHkces3DuvM871cPN8sm8dm9mkSq305s891n5yoW7yDklwz//qHkryru2+tqg8l+cPJplofN+7J4eiq+of1HIZ15/leLp5vls2NSe6+g+WPSPK1Bc+yQ958ePH+JcmTq+rAJMcn+cB8+T2S3DDZVOtjT8/tey3A5ub5Xi6eb5bNWUleVlXbP1Wiq+rBSV6V5B2TTbWCqFu830vyxiSXJ/nXJNs/FuyYJP801VAAwC69JLMDMFckOSCztyK7KMk3kvzGhHP9G6dfF6y7X19Vn0zywCQf2H4VbJKLk7x0uskAgJ3p7muTPKWq/mOSozI7MHZed39w2sm+SdQtUFUdkuRR3f3RJP+4avU1ST698KE2lrW+4JoxeL6Xi+ebTWvlz+/u/lBmFwptX/fkzN6W7OrJBpwTdYt1R5L3VtXx3f2x7Qur6tGZ/QU5bLLJ1sctVbUn7713xbpNwiJ4vpeL55tlsil+fou6Beru66rqrCTPTvKxFatOSvL+7r5ymsnWzaVJ7rcH21+2XoMsUlW9OXu235/r7heu1zwL5PleG8/3Jrasz/ey7vd2m+Xnt6hbvDOS/FlV/WJ33zL/hImfzSb4oOA74eFJnpC1nXapfPOikc3ukZnt91qMtN+e790bab8937tnv8ey4X9+i7rF+0Bm73VzQpJ3Jjkuyb5J/nLKodZJdfcta964apTX3HR337zWjcfZbc/3Woyz257vtRhnt5d2v1fa8D+/vaXJgs2vdj0zs0O4yezQ7Z93963TTbVuvI/VcvF8LxfPN0tlM/z8dqRuGmck+ceqemCSZ2RW+wDAxrahf347UjeB7v7nJBcmeVOSy7v7ExOPBADsxkb/+e1I3XTOSPI/k/z6xHOsp++oqt9c47YjvQDDfu+e/d787Pfu2e8xbdif39XtZQ5TqKp7JPnFJK/v7q9MPc96qKpjknzHHtzkG9197nrNsyj2e83s9yZmv9fMfg9mI//8FnUAAAPwmjoAgAGIOgCAAYi6CVXVqVPPMAX7vVzs93Kx38vFfm8som5aG/IvxQLY7+Viv5eL/V4u9nsDEXUAAANY+qtf9639ev8cOMlj35qbs0/2m+Sx+5ADJnncJLn1lm3ZZ99p/swf/qArJ3ncJLni67fn3vfce5LHvvDKe0/yuEly+7Zt2fvAaZ7v/b625o+qvMvdcseN2XevPXkHiLtO337bJI+bJLf2zdmnpvnv2uzz1adxS9+UfWv/SR579ulV05jy+Z7y7fBu7Zuyz0TP93V91ZXdvcP/qC/9mw/vnwPz+NpQn/KxEDcd87ipR5jE327dOvUIk3jE/3nh1CNM4rt//6KpR5jEHVdfPfUIk6jvmCaip9Y33jj1CNPYe5r/SZ7aB25602U7W+f0KwDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwADu0qirqg9X1R/clfcJAMDuOVIHADCADRt1VbXv1DMAAGwW6xp1VXVcVV1TVT9fVUdW1Qer6saquqqqTq+qQ1Zse3pVvbuqfrWqLk9y+Xz5YVX1lqq6ev7rPVX10BW3O6Kqzqqqr1TVtqo6r6pOWM/9AgDYaNYt6qrqxCTvSnJqkjcmeX+S65M8LskzkjwpyZ+sutlTkzwqyQ8nOa6qDkhydpKb5uuemOTLST44X5ckByV5b5IfTPLoJO9I8s6qesR67RsAwEazZT3utKpOTfLqJCd2919X1fOTHJjkpO6+bsU2Z1fVQ7r7ovlNb0pySnffPN/mlCSV5Lnd3fNlL0jytSQnJHlrd5+f5PwVD/+KqvqxJCcm+e1dzHdqkuyfA3a0CQDAprIeUfcTSV6Q5JjuPme+7JFJLtgedHMfT3JHku9Jsj3qLtwedHOPTXJ4kuuqauVjHJDkiCSpqgOTvCyzyLt/kn2S7J/kgp0N2N1bk2xNkoPrHr3HewgAsMGsR9Sdn+TIJM+rqnO3H2HbhZXrt61at1eSTyV55g5ud9X899MyO137kiRfSHJDkjOSuNACAFga6/GaukuTHJvkh5Jsrdkhts8kObKq7rZiuyfNH/8zu7iv85I8JMmV3X3Rql/bo+4pSc7o7nd09wWZXWBxxF27SwAAG9u6XCjR3ZckeVpmR9Ben+TNmR9Bm18Fe8x8+TtXvJ5uR96U5KtJzqqqp1bV4VV1TFW9ZsUVsJ9P8oyqOqqqjkxyZmanXwEAlsa6Xf3a3RdndsTuR5K8NsnxSQ5O8okkZyU5J8kpu7mPG5Ick+SSJG9L8tkkb0hy9yRXzzd7cWYXTnw0s6tgz51/DQCwNO7S19R197Grvr84yQNWLDpuF7d9zk6WfzXJc3dxu8uSPH3V4tN2MyoAwFA27CdKAACwdqIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYABbph6AaVzxmOV86j9843L+f8z+V9bUI0yituw99QiT2Puw+089wjT2Ws5/37dddvnUI0xiy2H3mXqEaXxx56uW818AAMBgRB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAANnXUVdXpVfXuqecAAJjalqkH+Da9KElNPQQAwNQ2ddR19zemngEAYCMY5vRrVR1TVedW1fVV9Y2q+kRVfd/UMwIALMKmPlK3XVVtSXJWkj9O8nNJ9klyVJLbp5wLAGBRhoi6JAcnOTTJX3b3xfNln93ZxlV1apJTk2T/HLDuwwEArLdNffp1u+6+KsnpSd5fVe+pqhdX1QN3sf3W7j66u4/eJ/stbE4AgPUyRNQlSXc/N8njk3wkyY8n+VxVHT/tVAAAizFM1CVJd5/f3a/q7mOTfDjJydNOBACwGENEXVUdXlX/o6qeVFUPqqqnJXlUkk9PPRsAwCKMcqHEDUkeluRtSe6V5KtJ3pTkVVMOBQCwKJs66rr7OSu+/cmp5gAAmNoQp18BAJadqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYgKgDABiAqAMAGICoAwAYwJapB2AaB3/xjqlHmMSv/NYLph5hElv26alHmMStD77v1CNMYssXLp96hElc8eMPm3qESdz775bzR/lFJ91n6hGm8Rs7X+VIHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAO7SqKuqD1fVH9yV9wkAwO45UgcAMIANG3VVte/UMwAAbBbrGnVVdVxVXVNVP19VR1bVB6vqxqq6qqpOr6pDVmx7elW9u6p+taouT3L5fPlhVfWWqrp6/us9VfXQFbc7oqrOqqqvVNW2qjqvqk5Yz/0CANho1i3qqurEJO9KcmqSNyZ5f5LrkzwuyTOSPCnJn6y62VOTPCrJDyc5rqoOSHJ2kpvm656Y5MtJPjhflyQHJXlvkh9M8ugk70jyzqp6xHrtGwDARrNlPe60qk5N8uokJ3b3X1fV85McmOSk7r5uxTZnV9VDuvui+U1vSnJKd9883+aUJJXkud3d82UvSPK1JCckeWt3n5/k/BUP/4qq+rEkJyb57V3Md2qS7J8DdrQJAMCmsh5R9xNJXpDkmO4+Z77skUku2B50cx9PckeS70myPeou3B50c49NcniS66pq5WMckOSIJKmqA5O8LLPIu3+SfZLsn+SCnQ3Y3VuTbE2Sg+sevcd7CACwwaxH1J2f5Mgkz6uqc7cfYduFleu3rVq3V5JPJXnmDm531fz30zI7XfuSJF9IckOSM5K40AIAWBrr8Zq6S5Mcm+SHkmyt2SG2zyQ5sqrutmK7J80f/zO7uK/zkjwkyZXdfdGqX9uj7ilJzujud3T3BZldYHHEXbtLAAAb27pcKNHdlyR5WmZH0F6f5M2ZH0GbXwV7zHz5O1e8nm5H3pTkq0nOqqqnVtXhVXVMVb1mxRWwn0/yjKo6qqqOTHJmZqdfAQCWxrpd/drdF2d2xO5Hkrw2yfFJDk7yiSRnJTknySm7uY8bkhyT5JIkb0vy2SRvSHL3JFfPN3txZhdOfDSzq2DPnX8NALA07tLX1HX3sau+vzjJA1YsOm4Xt33OTpZ/Nclzd3G7y5I8fdXi03YzKgDAUDbsJ0oAALB2og4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAKIOAGAAog4AYACiDgBgAFumHmBq33Xk9Xn1u8+deoyF++UHTz3BRKqmnmASe+2339QjTGKvQw+ZeoRJ3Hbl16ceYRL3ef9lU48wieu//7umHmESD3rfjVOPMImLdrHOkToAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABiDoAgAGIOgCAAYg6AIABLGXUVdWpVfXJqvrkNVfdMfU4AADftqWMuu7e2t1Hd/fRh95jKf8IAIDBKBoAgAGIOgCAAQwbdVX1C1X12annAABYhGGjLsm9kjx86iEAABZh2Kjr7pd3d009BwDAIgwbdQAAy0TUAQAMQNQBAAxA1AEADEDUAQAMQNQBAAxA1AEADEDUAQAMQNQBAAxA1AEADEDUAQAMQNQBAAxA1AEADEDUAQAMQNQBAAxA1AEADEDUAQAMQNQBAAxA1AEADEDUAQAMQNQBAAxA1AEADEDUAQAMQNQBAAxgy9QDTO2SbffOT//D86ceY+EeWBdOPcIkat99px5hEn3bbVOPMIk7rvnG1COwQL1t29QjTOKgT39t6hEm0Vf7972aI3UAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAPYNFFXVS+pqi9OPQcAwEa0aaIOAICdu0uirqoOrqpD74r72oPHvHdV7b/IxwQA2KjudNRV1d5VdXxVvTnJV5I8er78kKraWlVfq6rrqupvq+roFbd7TlVdX1XHVdWFVbWtqs6uqsNX3f+vVNVX5tuekeSgVSP8aJKvzB/ryXd2PwAARrDHUVdV31tVv5vk/yX58yTbkvxwko9UVSV5T5LDkpyQ5PuTfCTJh6rq/ivuZr8kv5bklCRPTHJokv+94jF+KslvJ3lZkqOSfC7Ji1eN8qYkP5vkbkk+UFUXVdVvro5DAIBlsKaoq6p7VtUvVdU/Jvm/SR6R5EVJ7tfdz+/uj3R3J3laksckObG7P9HdF3X3S5NckuSkFXe5Jcl/nW9zQZLTkhw7j8Ik+W9J3tDdr+/uz3f3K5J8YuVM3X1bd/9Vd/9Mkvsl+Z3543+hqj5cVadU1eqje9v359Sq+mRVffL2a7et5Y8AAGBDW+uRul9M8rokNyV5WHf/eHe/rbtvWrXdY5MckOSK+WnT66vq+iTfl+SIFdvd3N2fW/H9l5Lsm+Tu8+8fmeScVfe9+vt/093XdvefdPfTkvyHJPdN8sdJTtzJ9lu7++juPnrvgw/cxW4DAGwOW9a43dYktyZ5dpILq+pdSd6Y5G+6+/YV2+2V5KtJfmAH93Htiq9vW7WuV9x+j1XVfpmd7n1WZq+1++fMjvaddWfuDwBgs1lTRHX3l7r7Fd398CRPT3J9krckubyqXlNVj5lvel5mR8numJ96Xfnra3sw12eSPGHVsn/3fc08papen9mFGr+f5KIkj+3uo7r7dd199R48JgDAprXHR8a6+9zufmGS+2d2WvZhSf6hqn4gyQeTfCzJWVX1I1V1eFU9sar++3z9Wr0uyclV9fyqemhV/VqSx6/a5llJ/jrJwUl+JskDuvuXu/vCPd0nAIDNbq2nX79Fd9+c5O1J3l5V90lye3d3Vf1oZleu/lGS+2R2OvZjSc7Yg/v+86r67iSvyOw1en+R5PeSPGfFZn+T2YUa137rPQAALJc7HXUrrTy12t3XZXZl7It2su3pSU5ftezDSWrVslcmeeWqm798xfov3fmJAQDG4mPCAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABiDqAAAGIOoAAAYg6gAABrBl6gGmtu8lN+aB/+Wfph6DBembb556BBaob7tt6hFYoNuv+cbUI0xjWfebb+FIHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwABEHQDAAEQdAMAARB0AwAC2TD3AFKrq1CSnJsn+OWDiaQAAvn1LeaSuu7d299HdffQ+2W/qcQAAvm1LGXUAAKMRdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAAxB1AAADEHUAAAMQdQAAA6junnqGSVXVFUkum+jh75Xkyokee0r2e7nY7+Viv5eL/V68B3X3vXe0YumjbkpV9cnuPnrqORbNfi8X+71c7Pdysd8bi9OvAAADEHUAAAMQddPaOvUAE7Hfy8V+Lxf7vVzs9wbiNXUAAANwpA4AYACiDgBgAKIOAGAAog4AYACiDgBgAP8fv8Kry3AM+kEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('한국은 훌륭한 나라이다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "216763c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 한국 의 소중 한 문화 <end>\n",
      "Predicted translation: the south cultural team to play to be together . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161/4081095973.py:49: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_161/4081095973.py:50: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49548 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51473 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47928 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54868 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49548 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51473 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47928 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54868 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"한국의 소중한 문화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1f7d64b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 공부 가 재미있 다 <end>\n",
      "Predicted translation: these things are good . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161/4081095973.py:49: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_161/4081095973.py:50: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44277 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48512 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44032 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44277 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48512 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44032 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"공부가 재미있다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee9646",
   "metadata": {},
   "source": [
    "# 실험종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959b2b4",
   "metadata": {},
   "source": [
    "기존의 데이터로는 학습이 다소 어려워, 다른 한영 말뭉치를 통해 학습을 추가적으로 진행했으며, 코드는 구글의 예제 코드를 따왔다\n",
    "하는 과정에서 전처리 과정에 따라 많은 에러를 겪었으며, 코드가 복잡해지다보니 군데군데 에러가 발생하는 구간이 많아 오래 걸리게 되었다\n",
    "아직까지 커스텀 루프를 통한 모델 학습에는 좀 더 이해도가 필요할 것으로 보인다  \n",
    "학습이 빨리 이루어지지 않아 성능 확인과 개선에 시간이 오래 걸렸으며, 이를 위해 커스텀 학습 루프에 적응 후 병렬 학습에 대한 적응을 할 필요가 있었다  \n",
    "좀 더 많은 데이터를 썼으면 하는 아쉬움이 남는다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
